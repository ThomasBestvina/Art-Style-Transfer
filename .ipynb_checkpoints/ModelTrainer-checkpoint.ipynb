{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00cbff1b-0e68-407b-aced-b335f182e3db",
   "metadata": {},
   "source": [
    "# Initalize and install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9cf912-9a35-438b-a72b-97420ef38c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ae0fc3-a577-4f66-a29b-320cbcce30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"\"\n",
    "monet_path = \"inputs/\"\n",
    "photo_path = \"outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c1e344b-cf45-4012-9b35-966165b1ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonetPhoto(Dataset):\n",
    "    def __init__(self, data_root, monet_path, photo_path, transform=None):\n",
    "        self.data_root = data_root\n",
    "        self.monet_path = monet_path\n",
    "        self.monet_images = os.listdir(os.path.join(data_root, monet_path))\n",
    "        self.photo_path = photo_path\n",
    "        self.photo_images = os.listdir(os.path.join(data_root, photo_path))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.monet_images), len(self.photo_images))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        monet_image = Image.open(os.path.join(data_root, monet_path, self.monet_images[idx % len(self.monet_images)]))\n",
    "        photo_image = Image.open(os.path.join(data_root, photo_path, self.photo_images[idx % len(self.photo_images)]))\n",
    "        if self.transform:\n",
    "            monet_image = self.transform(monet_image)\n",
    "            photo_image = self.transform(photo_image)\n",
    "        return monet_image, photo_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ad9589-2bc3-4163-9af4-d43d1f95c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((256,256)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "dataset = MonetPhoto(data_root, monet_path, photo_path, transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59e99f7-ac7b-4660-a58c-aab0684bd30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, test_size = int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95eb5b4c-9421-44f4-854c-c2092645c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, testing_data = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced2d519-8979-4080-b0c4-b686d0dc5717",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data.dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(testing_data.dataset, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fa8bec3-5390-4dd2-b13a-da9318d7bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c930b3f3-71e3-497c-a3b7-5d0b9133cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=2, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, stride, bias=False, padding_mode='reflect', device=self.device),\n",
    "            nn.BatchNorm2d(out_channels, device=self.device),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7ea7936-75a6-4f72-b368-566c272bfeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=[64, 128, 256, 512], device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features[0], kernel_size=4, stride=2, padding=1, padding_mode='reflect', device=self.device),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        layers = []\n",
    "        in_channels = features[0]\n",
    "        for feature in features[1:]:\n",
    "            layers.append(\n",
    "                CNNBlock(in_channels, feature, stride=1 if feature == features[-1] else 2, device=self.device),\n",
    "            )\n",
    "            in_channels = feature\n",
    "        \n",
    "        layers.append(\n",
    "            nn.Conv2d(\n",
    "                in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode='reflect', device=self.device\n",
    "            )\n",
    "        )\n",
    "            \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d10fa954-1864-4373-b353-e12962e1c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, down=True, act = 'relu', use_dropout=False, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 4, 2, 1, bias=False, padding_mode='reflect', device=self.device)\n",
    "            if down\n",
    "            else nn.ConvTranspose2d(in_channels, out_channels, 4, 2, 1, bias=False, device=self.device),\n",
    "            nn.BatchNorm2d(out_channels, device=self.device),\n",
    "            nn.ReLU() if act=='relu' else nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.dropout(x) if self.use_dropout else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "148d9e22-2e31-4e60-a8d8-b22bc2ea281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channels=3, features=64, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.initial_down = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features, 4, 2, 1, padding_mode='reflect', device=self.device),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        ) #128\n",
    "        \n",
    "        self.down1 = Block(features, features*2, down=True, act='leaky', use_dropout=False)   #64\n",
    "        self.down2 = Block(features*2, features*4, down=True, act='leaky', use_dropout=False) #32\n",
    "        self.down3 = Block(features*4, features*8, down=True, act='leaky', use_dropout=False) #16\n",
    "        self.down4 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #8\n",
    "        self.down5 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #4\n",
    "        self.down6 = Block(features*8, features*8, down=True, act='leaky', use_dropout=False) #2\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(features*8, features*8, 4, 2, 1, padding_mode='reflect', device=self.device), #1x1\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.up1 = Block(features*8, features*8, down=False, act='relu', use_dropout=True)\n",
    "        self.up2 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n",
    "        self.up3 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=True)\n",
    "        self.up4 = Block(features*8*2, features*8, down=False, act='relu', use_dropout=False)\n",
    "        self.up5 = Block(features*8*2, features*4, down=False, act='relu', use_dropout=False)\n",
    "        self.up6 = Block(features*4*2, features*2, down=False, act='relu', use_dropout=False)\n",
    "        self.up7 = Block(features*2*2, features, down=False, act='relu', use_dropout=False)\n",
    "        self.finil_up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(features*2, in_channels, kernel_size=4, stride=2, padding=1, device=self.device),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        d1 = self.initial_down(x)\n",
    "        d2 = self.down1(d1)\n",
    "        d3 = self.down2(d2)\n",
    "        d4 = self.down3(d3)\n",
    "        d5 = self.down4(d4)\n",
    "        d6 = self.down5(d5)\n",
    "        d7 = self.down6(d6)\n",
    "        \n",
    "        bottleneck = self.bottleneck(d7)\n",
    "        \n",
    "        up1 = self.up1(bottleneck)\n",
    "        up2 = self.up2(torch.cat([up1, d7], 1))\n",
    "        up3 = self.up3(torch.cat([up2, d6], 1))\n",
    "        up4 = self.up4(torch.cat([up3, d5], 1))\n",
    "        up5 = self.up5(torch.cat([up4, d4], 1))\n",
    "        up6 = self.up6(torch.cat([up5, d3], 1))\n",
    "        up7 = self.up7(torch.cat([up6, d2], 1))\n",
    "        \n",
    "        return self.finil_up(torch.cat([up7, d1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee68a93e-f778-4df9-ab72-95b8276f82de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file models already exists.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 225\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscriminator\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscriminator_weights.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    220\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmkdir models\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    222\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    223\u001b[0m         train_data \u001b[38;5;241m=\u001b[39m train_dataloader,\n\u001b[0;32m    224\u001b[0m         val_data \u001b[38;5;241m=\u001b[39m test_dataloader,\n\u001b[1;32m--> 225\u001b[0m         generator \u001b[38;5;241m=\u001b[39m Generator(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m),\n\u001b[0;32m    226\u001b[0m         discriminator \u001b[38;5;241m=\u001b[39m Discriminator(),\n\u001b[0;32m    227\u001b[0m         nb_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m,\n\u001b[0;32m    228\u001b[0m         device \u001b[38;5;241m=\u001b[39m device,\n\u001b[0;32m    229\u001b[0m         save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    230\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[15], line 6\u001b[0m, in \u001b[0;36mGenerator.__init__\u001b[1;34m(self, in_channels, features, device)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_down \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m----> 6\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels, features, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, padding_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m'\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[0;32m      7\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLeakyReLU(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[0;32m      8\u001b[0m ) \u001b[38;5;66;03m#128\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1 \u001b[38;5;241m=\u001b[39m Block(features, features\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, down\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, act\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleaky\u001b[39m\u001b[38;5;124m'\u001b[39m, use_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)   \u001b[38;5;66;03m#64\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown2 \u001b[38;5;241m=\u001b[39m Block(features\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, features\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m, down\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, act\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleaky\u001b[39m\u001b[38;5;124m'\u001b[39m, use_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#32\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:521\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    519\u001b[0m padding_ \u001b[38;5;241m=\u001b[39m padding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _pair(padding)\n\u001b[0;32m    520\u001b[0m dilation_ \u001b[38;5;241m=\u001b[39m _pair(dilation)\n\u001b[1;32m--> 521\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    522\u001b[0m     in_channels,\n\u001b[0;32m    523\u001b[0m     out_channels,\n\u001b[0;32m    524\u001b[0m     kernel_size_,\n\u001b[0;32m    525\u001b[0m     stride_,\n\u001b[0;32m    526\u001b[0m     padding_,\n\u001b[0;32m    527\u001b[0m     dilation_,\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    529\u001b[0m     _pair(\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    530\u001b[0m     groups,\n\u001b[0;32m    531\u001b[0m     bias,\n\u001b[0;32m    532\u001b[0m     padding_mode,\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs,\n\u001b[0;32m    534\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:166\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[0;32m    159\u001b[0m         torch\u001b[38;5;241m.\u001b[39mempty(\n\u001b[0;32m    160\u001b[0m             (in_channels, out_channels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m groups, \u001b[38;5;241m*\u001b[39mkernel_size),\n\u001b[0;32m    161\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs,\n\u001b[0;32m    162\u001b[0m         )\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\n\u001b[1;32m--> 166\u001b[0m         torch\u001b[38;5;241m.\u001b[39mempty(\n\u001b[0;32m    167\u001b[0m             (out_channels, in_channels \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m groups, \u001b[38;5;241m*\u001b[39mkernel_size),\n\u001b[0;32m    168\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs,\n\u001b[0;32m    169\u001b[0m         )\n\u001b[0;32m    170\u001b[0m     )\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_channels, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:310\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    314\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data: DataLoader,\n",
    "        val_data: DataLoader,\n",
    "        generator: torch.nn.Module,\n",
    "        discriminator: torch.nn.Module,\n",
    "        nb_epochs: int = 5,\n",
    "        device: str = \"cuda\",\n",
    "        save_path: str = None,\n",
    "    ):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.nb_epochs = nb_epochs\n",
    "        self.device = device\n",
    "        self.save_path = Path(save_path) if save_path else save_path\n",
    "\n",
    "        self.z = next(iter(self.val_data))[0][:32].to(self.device)\n",
    "        \n",
    "        self.logs = {\n",
    "            \"Step\": [],\n",
    "            \"Train_g_loss\": [],\n",
    "            \"Train_d_loss\": [],\n",
    "            \"Val_g_loss\": [],\n",
    "            \"Val_d_loss\": [],\n",
    "            \"Samples\": [],\n",
    "        }\n",
    "\n",
    "    def init_optimizers(self, lr: float=3e-4, betas: tuple=(0.5, 0.999)):\n",
    "        self.g_optimizer = torch.optim.Adam(\n",
    "            self.generator.parameters(), lr=lr, betas=betas\n",
    "        )\n",
    "        self.d_optimizer = torch.optim.Adam(\n",
    "            self.discriminator.parameters(), lr=lr, betas=betas\n",
    "        )\n",
    "\n",
    "    def train(self):\n",
    "        assert (self.g_optimizer is not None) and (\n",
    "            self.d_optimizer is not None\n",
    "        ), \"Please run Trainer().init_optimizer()\"\n",
    "\n",
    "        # Loading best model\n",
    "        if self.save_path and self.save_path.exists():\n",
    "            self.load_model()\n",
    "            \n",
    "        best_score = torch.inf\n",
    "\n",
    "        for i in range(self.nb_epochs):\n",
    "            train_d_loss, train_g_loss, val_d_loss, val_g_loss = 0, 0, 0, 0\n",
    "            self.generator.train()\n",
    "            self.discriminator.train()\n",
    "            # Train loop\n",
    "            loop = tqdm(\n",
    "                enumerate(self.train_data),\n",
    "                desc=f\"Epoch {i + 1}/{self.nb_epochs} train\",\n",
    "                leave=False,\n",
    "                total=len(self.train_data),\n",
    "            )\n",
    "            for step, (x, y) in loop:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                # Train step\n",
    "                g_loss, d_loss = self.train_step(x, y)\n",
    "\n",
    "                train_g_loss += g_loss\n",
    "                train_d_loss += d_loss\n",
    "\n",
    "                loop.set_postfix_str(\n",
    "                    f\"g_loss: {train_g_loss / (step + 1) :.2f}, d_loss: {train_d_loss / (step + 1) :.2f}\"\n",
    "                )\n",
    "\n",
    "            # Validation loop\n",
    "            self.generator.eval()\n",
    "            self.discriminator.eval()\n",
    "\n",
    "            loop = tqdm(\n",
    "                enumerate(self.val_data),\n",
    "                desc=f\"Epoch {i + 1}/{self.nb_epochs} validation\",\n",
    "                leave=True,\n",
    "                total=len(self.val_data),\n",
    "            )\n",
    "            for step, (x, y) in loop:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "\n",
    "                # Validation step\n",
    "                g_loss, d_loss = self.val_step(x, y)\n",
    "\n",
    "                val_g_loss += g_loss\n",
    "                val_d_loss += d_loss\n",
    "\n",
    "                loop.set_postfix_str(\n",
    "                    f\"g_loss: {val_g_loss / (step + 1) :.2f} d_loss: {val_d_loss / (step + 1) :.2f}\"\n",
    "                )\n",
    "\n",
    "            # Saving best model\n",
    "            if self.save_path and best_score > val_g_loss:\n",
    "                best_score = val_g_loss\n",
    "                self.save_model()\n",
    "\n",
    "            # Log\n",
    "            self.log_metrics(\n",
    "                step=i,\n",
    "                train_g_loss=train_g_loss,\n",
    "                train_d_loss=train_d_loss,\n",
    "                val_g_loss=val_g_loss,\n",
    "                val_d_loss=val_d_loss,\n",
    "            )\n",
    "            # plot\n",
    "            fake_img = self.generator((photos[0].unsqueeze(0)).to('cuda'))\n",
    "            fake_img = fake_img[0].cpu().detach()\n",
    "            \n",
    "            fig, ax = plt.subplots(1, 2, figsize=(20, 4))\n",
    "            ax[0].imshow(photos[0].permute(1, 2, 0).numpy() * 0.5 + 0.5)\n",
    "            ax[0].set_title(\"Photo\")\n",
    "            ax[0].set(xticks=[], yticks=[])\n",
    "            ax[1].imshow(fake_img.permute(1, 2, 0).numpy() * 0.5 + 0.5  )\n",
    "            ax[1].set_title(\"FakeMonet\")\n",
    "            ax[1].set(xticks=[], yticks=[])\n",
    "            plt.show()\n",
    "            \n",
    "        return self.logs\n",
    "\n",
    "    def train_step(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor\n",
    "    ) -> tuple:\n",
    "        self.g_optimizer.zero_grad(set_to_none=True)\n",
    "        self.d_optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        fake_ = self.discriminator(\n",
    "            self.generator(x)\n",
    "        )\n",
    "        real = self.discriminator(y)\n",
    "        d_loss = (\n",
    "            torch.nn.functional.mse_loss(real, torch.ones_like(real, device=self.device)) + \n",
    "            torch.nn.functional.mse_loss(fake_, torch.zeros_like(fake_, device=self.device))\n",
    "        )\n",
    "\n",
    "        d_loss.backward()\n",
    "        self.d_optimizer.step()\n",
    "        \n",
    "        fake = self.discriminator(\n",
    "            self.generator(x)\n",
    "        )\n",
    "        \n",
    "        g_loss = torch.nn.functional.mse_loss(fake, torch.ones_like(fake, device=self.device))\n",
    "        g_loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "\n",
    "        return g_loss.item(), d_loss.item()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def val_step(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "    ) -> tuple:\n",
    "        fake = self.discriminator(\n",
    "            self.generator(x)\n",
    "        )\n",
    "        real = self.discriminator(y)\n",
    "        g_loss = torch.nn.functional.mse_loss(fake, torch.ones_like(fake, device=self.device))\n",
    "        d_loss = (\n",
    "            torch.nn.functional.mse_loss(real, torch.ones_like(real, device=self.device)) + \n",
    "            torch.nn.functional.mse_loss(fake, torch.zeros_like(fake, device=self.device))\n",
    "        )\n",
    "        return g_loss.item(), d_loss.item()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def log_metrics(\n",
    "        self,\n",
    "        step: int,\n",
    "        train_g_loss: torch.Tensor,\n",
    "        train_d_loss: torch.Tensor,\n",
    "        val_g_loss: torch.Tensor,\n",
    "        val_d_loss: torch.Tensor,\n",
    "    ):\n",
    "        self.logs[\"Step\"].append(step)\n",
    "        self.logs[\"Train_g_loss\"].append(train_g_loss / len(self.train_data))\n",
    "        self.logs[\"Train_d_loss\"].append(train_d_loss / len(self.train_data))\n",
    "        self.logs[\"Val_g_loss\"].append(val_g_loss / len(self.val_data))\n",
    "        self.logs[\"Val_d_loss\"].append(val_d_loss / len(self.val_data))\n",
    "        self.logs[\"Samples\"].append(make_grid(self.generator(self.z).cpu() * 0.5 + 0.5, normalize=True))\n",
    "\n",
    "    def save_model(self, full: bool = False):\n",
    "        if full:\n",
    "            torch.save(self.generator, Path(self.save_path) / \"generator.pth\")\n",
    "            torch.save(self.discriminator, Path(self.save_path) / \"discriminator.pth\")\n",
    "        else:\n",
    "            torch.save(\n",
    "                self.generator.state_dict(),\n",
    "                Path(self.save_path) / \"generator_weights.pth\",\n",
    "            )\n",
    "            torch.save(\n",
    "                self.discriminator.state_dict(),\n",
    "                Path(self.save_path) / \"discriminator_weights.pth\",\n",
    "            )\n",
    "\n",
    "    def load_model(self, full: bool = False):\n",
    "        if (\n",
    "            full\n",
    "            and (self.save_path / \"generator.pth\").is_file()\n",
    "            and (self.save_path / \"discriminator.pth\").is_file()\n",
    "        ):\n",
    "            self.generator = torch.load(self.save_path / \"generator.pth\")\n",
    "            self.discriminator = torch.load(self.save_path / \"discriminator.pth\")\n",
    "        elif (\n",
    "            self.save_path / \"generator_weights.pth\"\n",
    "        ).is_file() and (\n",
    "            self.save_path / \"discriminator_weights.pth\"\n",
    "        ).is_file():\n",
    "            self.generator.load_state_dict(torch.load(self.save_path / \"generator_weights.pth\"))\n",
    "            self.discriminator.load_state_dict(torch.load(self.save_path / \"discriminator_weights.pth\"))\n",
    "\n",
    "!mkdir models\n",
    "\n",
    "trainer = Trainer(\n",
    "        train_data = train_dataloader,\n",
    "        val_data = test_dataloader,\n",
    "        generator = Generator(in_channels=3, features=64),\n",
    "        discriminator = Discriminator(),\n",
    "        nb_epochs = 30,\n",
    "        device = device,\n",
    "        save_path = './models/'\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491c8bb-62fa-40d1-bbe8-ee9eb0ea8880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
